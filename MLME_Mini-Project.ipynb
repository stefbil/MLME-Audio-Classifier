{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGfeNVZYPK6W"
      },
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EfRzZPN8PF67"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras import layers, models, regularizers, optimizers\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import librosa\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RagIB02Jy4J",
        "outputId": "ab896fab-0703-4f40-9987-d151e0d45c5e"
      },
      "outputs": [],
      "source": [
        "# Download/Exract Dataset\n",
        "DATA_DIR = './data'\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    os.makedirs(DATA_DIR)\n",
        "\n",
        "url = \"https://www.openslr.org/resources/17/musan.tar.gz\"\n",
        "filename = os.path.join(DATA_DIR, \"musan.tar.gz\")\n",
        "\n",
        "def download_with_progress(url, filename):\n",
        "    \"\"\"Download a file from a URL.\"\"\"\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
        "    block_size = 1024 # 1 Kibibyte\n",
        "\n",
        "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
        "    with open(filename, 'wb') as file:\n",
        "        for data in response.iter_content(block_size):\n",
        "            progress_bar.update(len(data))\n",
        "            file.write(data)\n",
        "    progress_bar.close()\n",
        "\n",
        "# Download\n",
        "if not os.path.exists(filename):\n",
        "    print(\"Downloading MUSAN dataset... (aprox. 15-20mins)\")\n",
        "    download_with_progress(url, filename)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "# Extract\n",
        "print(\"Extracting...\")\n",
        "with tarfile.open(filename, \"r:gz\") as tar:\n",
        "    tar.extractall(path=DATA_DIR)\n",
        "print(\"Extraction complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx5CGiobOIJR",
        "outputId": "3f24c254-789d-4cbd-edd1-ae58d86e0103"
      },
      "outputs": [],
      "source": [
        "# HD Configuration\n",
        "DATA_DIR = './data'\n",
        "SAMPLE_RATE = 16000\n",
        "DURATION = 3\n",
        "N_MELS = 128\n",
        "HOP_LENGTH = 512\n",
        "N_FFT = 2048 # Increased fft for better detail\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
        "\n",
        "# Help function\n",
        "def extract_log_melspectrogram(file_path):\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
        "        if len(y) == 0 or np.max(np.abs(y)) == 0:\n",
        "            return np.zeros((N_MELS, int(np.ceil(SAMPLES_PER_TRACK / HOP_LENGTH)), 1))\n",
        "\n",
        "        y = y / np.max(np.abs(y))\n",
        "\n",
        "        if len(y) < SAMPLES_PER_TRACK:\n",
        "            y = np.pad(y, (0, SAMPLES_PER_TRACK - len(y)))\n",
        "        else:\n",
        "            y = y[:SAMPLES_PER_TRACK]\n",
        "\n",
        "        # HD Mel Spectrogram\n",
        "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
        "        mel = np.maximum(mel, 1e-10)\n",
        "        log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "        # Normalize\n",
        "        log_mel = (log_mel + 80) / 80.0\n",
        "        return np.clip(log_mel, 0, 1)[..., np.newaxis]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return np.zeros((N_MELS, int(np.ceil(SAMPLES_PER_TRACK / HOP_LENGTH)), 1))\n",
        "\n",
        "# Data and balancing\n",
        "all_music = glob(f'{DATA_DIR}/musan/music/**/*.wav', recursive=True)[:500]\n",
        "all_speech = glob(f'{DATA_DIR}/musan/speech/**/*.wav', recursive=True)[:500]\n",
        "all_noise = glob(f'{DATA_DIR}/musan/noise/**/*.wav', recursive=True)[:500]\n",
        "\n",
        "files = all_music + all_speech + all_noise\n",
        "labels = (['music'] * len(all_music)) + (['speech'] * len(all_speech)) + (['noise'] * len(all_noise))\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(labels)\n",
        "X_train, X_val, y_train, y_val = train_test_split(files, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "# Generator with Safe Augmentation\n",
        "class AudioGenerator(Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size=32, augment=False):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        X_batch = []\n",
        "\n",
        "        for f in batch_x:\n",
        "            try:\n",
        "                y, sr = librosa.load(f, sr=SAMPLE_RATE, duration=DURATION)\n",
        "\n",
        "                # Raw Audio Augmentation\n",
        "                if self.augment:\n",
        "                    # Time Shift\n",
        "                    if np.random.random() < 0.5:\n",
        "                        shift = np.random.randint(len(y) * 0.2)\n",
        "                        y = np.roll(y, shift)\n",
        "                    # Gain\n",
        "                    if np.random.random() < 0.5:\n",
        "                        y = y * np.random.uniform(0.8, 1.2)\n",
        "\n",
        "                # Preprocessing\n",
        "                if len(y) < SAMPLES_PER_TRACK:\n",
        "                    y = np.pad(y, (0, SAMPLES_PER_TRACK - len(y)))\n",
        "                else:\n",
        "                    y = y[:SAMPLES_PER_TRACK]\n",
        "\n",
        "                mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
        "                mel = np.maximum(mel, 1e-10)\n",
        "                log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "                spec = np.clip((log_mel + 80) / 80.0, 0, 1)\n",
        "\n",
        "                # Spectrogram Augmentation\n",
        "                if self.augment:\n",
        "                    # Frequency Masking\n",
        "                    if np.random.random() < 0.5:\n",
        "                        num_freqs = N_MELS\n",
        "                        f_width = np.random.randint(1, int(num_freqs * 0.15)) # Mask up to 15%\n",
        "                        f_start = np.random.randint(0, num_freqs - f_width)\n",
        "                        spec[f_start:f_start+f_width, :] = 0\n",
        "\n",
        "                    # Time Masking\n",
        "                    if np.random.random() < 0.5:\n",
        "                        num_times = spec.shape[1]\n",
        "                        t_width = np.random.randint(1, int(num_times * 0.15)) # Mask up to 15%\n",
        "                        t_start = np.random.randint(0, num_times - t_width)\n",
        "                        spec[:, t_start:t_start+t_width] = 0\n",
        "\n",
        "                X_batch.append(spec[..., np.newaxis])\n",
        "\n",
        "            except:\n",
        "                X_batch.append(np.zeros((N_MELS, int(np.ceil(SAMPLES_PER_TRACK / HOP_LENGTH)), 1)))\n",
        "\n",
        "        return np.array(X_batch), np.array(batch_y)\n",
        "\n",
        "# Re-init\n",
        "train_gen = AudioGenerator(X_train, y_train, augment=True)\n",
        "val_gen = AudioGenerator(X_val, y_val, augment=False)\n",
        "print(\"Generator updated with SpecAugment.\")\n",
        "\n",
        "train_gen = AudioGenerator(X_train, y_train, augment=True)\n",
        "val_gen = AudioGenerator(X_val, y_val, augment=False)\n",
        "print(f\"Generators Ready. Input Shape: ({N_MELS}, {int(np.ceil(SAMPLES_PER_TRACK / HOP_LENGTH))}, 1)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "81lTcHgNvmSa",
        "outputId": "2e73f99a-3dec-401f-b594-32f6f969e49b"
      },
      "outputs": [],
      "source": [
        "# Get a batch\n",
        "X_batch, y_batch = val_gen[0]\n",
        "\n",
        "# Plot the first sample\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.imshow(X_batch[0].squeeze(), aspect='auto', origin='lower', cmap='viridis')\n",
        "plt.title(f\"Label: {y_batch[0]} (0=Music, 1=Noise, 2=Speech)\")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Data Stats - Min: {X_batch.min():.2f}, Max: {X_batch.max():.2f}, Mean: {X_batch.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "0PmYA7Amtb6K",
        "outputId": "5836eb95-8214-498a-b74b-766607952908"
      },
      "outputs": [],
      "source": [
        "# visualize and check data debug\n",
        "\n",
        "# Get one batch from the validation generator\n",
        "X_batch, y_batch = val_gen[0]\n",
        "\n",
        "print(f\"Batch Shape: {X_batch.shape}\")\n",
        "print(f\"Data Min: {X_batch.min()}, Data Max: {X_batch.max()}\")\n",
        "print(f\"Is the entire batch zeros? {np.all(X_batch == 0)}\")\n",
        "\n",
        "# Plot the first spectrogram in the batch\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.imshow(X_batch[0].squeeze(), aspect='auto', origin='lower', cmap='magma')\n",
        "plt.title(f\"Sample Spectrogram (Label: {y_batch[0]})\")\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.show()\n",
        "\n",
        "# Check if we have valid non-zero data\n",
        "if X_batch.max() == 0:\n",
        "    print(\"CRITICAL ERROR: Your data is all Zeros. Check your dataset path!\")\n",
        "else:\n",
        "    print(\"Data looks valid.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "6UgXM-ShORcR",
        "outputId": "8573ddd9-1c2f-4e7f-e820-6a841843bf05"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Input: (128 Mels, Time, 1)\n",
        "input_shape = (N_MELS, int(np.ceil(SAMPLES_PER_TRACK / HOP_LENGTH)), 1)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "\n",
        "    # Block 1 Wide\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 2 Capture Texture\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 3 Complex Patterns\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Aggregation\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "\n",
        "    # Classifier\n",
        "    layers.Dense(128, activation='relu'), # increased dense layer size\n",
        "    layers.Dropout(0.2), # dropout low for learning\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# standard adam\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dspfu_GYOWGW",
        "outputId": "2a70427d-fb62-4a6d-d84e-006896d176f4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=0.000001\n",
        ")\n",
        "\n",
        "# Train\n",
        "print(\"Starting training with lower learning rate...\")\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=25, # 25 because of the lower learning rate\n",
        "    validation_data=val_gen,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0LfwWwGvGAl",
        "outputId": "4892b529-2aa5-4aeb-c567-d3ae78dcbebf"
      },
      "outputs": [],
      "source": [
        "# Switch Generator to Clean Mode without Augmentation\n",
        "# for the model tosee clear, unmasked signals now\n",
        "train_gen_clean = AudioGenerator(X_train, y_train, augment=False)\n",
        "\n",
        "# Lower Learning Rate significantly to\n",
        "# prevent destroying the weights.\n",
        "# Standard Adam is 1e-3. Here I use 1e-5 (100x slower).\n",
        "optimizer_fine = optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "model.compile(optimizer=optimizer_fine,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-Tune\n",
        "print(\"Starting Phase 2: Fine-Tuning on clean data...\")\n",
        "history_fine = model.fit(\n",
        "    train_gen_clean,\n",
        "    epochs=10,  # Short run\n",
        "    validation_data=val_gen,\n",
        "    callbacks=[early_stop] # Keep early stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmAwKsSSOjOG",
        "outputId": "ad958a38-719e-4d58-a2fb-37b473c68fa8"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/models\n",
        "model.save(\"/content/models/audio_classifier.keras\")\n",
        "print(\"Keras model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EayXuXBxOaSI",
        "outputId": "68f4d905-2f9d-4a37-ca20-5d1296fc30d3"
      },
      "outputs": [],
      "source": [
        "# TFLite Conversion\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Enable SELECT_TF_OPS\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "\n",
        "# Convert\n",
        "try:\n",
        "    tflite_model = converter.convert()\n",
        "    with open('/content/models/model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(\"Success! TFLite model saved.\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fKG4pjV8PDoS",
        "outputId": "b37eaaf4-e48b-4fe5-dfec-25bdea9205b7"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "\n",
        "# Define Labels Map\n",
        "label_map = le.inverse_transform([0, 1, 2])\n",
        "print(f\"Class Mapping: {label_map}\")\n",
        "\n",
        "\n",
        "# EVALUATE KERAS MODEL (.h5)\n",
        "print(\"\\n Evaluating Keras Model (.h5)\")\n",
        "# Generate predictions for the whole validation set\n",
        "# the generator handles loading audio files efficiently\n",
        "y_pred_keras = []\n",
        "y_true = []\n",
        "\n",
        "# Iterate through validation generator\n",
        "print(\"Running inference on Keras model...\")\n",
        "for i in tqdm(range(len(val_gen))):\n",
        "    batch_x, batch_y = val_gen[i]\n",
        "    preds = model.predict(batch_x, verbose=0)\n",
        "\n",
        "    y_pred_keras.extend(np.argmax(preds, axis=1))\n",
        "    y_true.extend(batch_y)\n",
        "\n",
        "# EVALUATE TFLITE MODEL (.tflite)\n",
        "print(\"\\n Evaluating TFLite Model (.tflite)\")\n",
        "\n",
        "# Load TFLite Interpreter\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/models/model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "y_pred_tflite = []\n",
        "\n",
        "print(\"Running inference on TFLite model (this is slower as it runs 1-by-1)...\")\n",
        "# We manually load files here because TFLite usually processes single samples\n",
        "for file_path in tqdm(X_val):\n",
        "    # Process audio using the SAME function as training\n",
        "    # Output shape is (64, 94, 1) but needs to be (1, 64, 94, 1) for TFLite\n",
        "    input_data = extract_log_melspectrogram(file_path)\n",
        "    input_data = np.expand_dims(input_data, axis=0).astype(np.float32)\n",
        "\n",
        "    # Run Inference\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    y_pred_tflite.append(np.argmax(output_data))\n",
        "\n",
        "# VISUALIZATION\n",
        "def plot_evaluation(y_true, y_pred, title):\n",
        "    print(f\"\\nClassification Report for {title}:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=label_map))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=label_map, yticklabels=label_map)\n",
        "    plt.title(f'Confusion Matrix: {title}')\n",
        "    plt.ylabel('Actual Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Show Results\n",
        "# y_true matches y_pred_keras. For tflite, iterated X_val directly.\n",
        "# need y_val (encoded labels) to match the order of X_val.\n",
        "plot_evaluation(y_true, y_pred_keras, \"Keras Model\")\n",
        "plot_evaluation(y_val, y_pred_tflite, \"TFLite Model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TxydQIuQuW0l",
        "outputId": "5d966c2c-df6b-4d86-ab03-940095a42042"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load model\n",
        "model = load_model('/content/models/audio_classifier.keras')\n",
        "\n",
        "# Generate visualization\n",
        "plot_model(\n",
        "    model,\n",
        "    to_file='cnn_architecture.png',\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "092b869f249a46b7abb8644502dc77c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "147110aa744142a797cf04ddd9cc04b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_383fc694b0294a65aaead1605b056e52"
          }
        },
        "21029458513b481d9737ca4dc7701b87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279d40b1b1b940e0b93ccdac90c0b0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d85357c6f64479f86d25d35149c3113",
            "placeholder": "​",
            "style": "IPY_MODEL_599f72f9c64f4f1a8563a79f5104e9f9",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "2cf2240b184847319ad8766004ca699e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d85357c6f64479f86d25d35149c3113": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "383fc694b0294a65aaead1605b056e52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "38c97cb29486424691a997c005ae9c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3ca5038c4d8e4acb8838d174ecc806c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe18a661306448dbeff45ff3499606c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "423eff646deb42bb93f48b8798171f75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5755b4e7d0234cf39605be660e0ba086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_21029458513b481d9737ca4dc7701b87",
            "placeholder": "​",
            "style": "IPY_MODEL_3fe18a661306448dbeff45ff3499606c",
            "value": ""
          }
        },
        "599f72f9c64f4f1a8563a79f5104e9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b75aed7e8d44422b65fd5715ff9f20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a279a32992340d8b2d2be684b3536f8",
            "placeholder": "​",
            "style": "IPY_MODEL_092b869f249a46b7abb8644502dc77c3",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "6a279a32992340d8b2d2be684b3536f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6abdca09cb496aa995efc859949f99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81793e74048945cbba84f7e36c847170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3ca5038c4d8e4acb8838d174ecc806c0",
            "style": "IPY_MODEL_38c97cb29486424691a997c005ae9c51",
            "tooltip": ""
          }
        },
        "98ece558edd34988ad5943f056cccbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_423eff646deb42bb93f48b8798171f75",
            "style": "IPY_MODEL_c0631242d47940f3b8dc4da2858fe9ac",
            "value": false
          }
        },
        "c0631242d47940f3b8dc4da2858fe9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4d4347d835942d096acec59dfa44868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d6abdca09cb496aa995efc859949f99",
            "placeholder": "​",
            "style": "IPY_MODEL_2cf2240b184847319ad8766004ca699e",
            "value": "Connecting..."
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
